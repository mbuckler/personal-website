<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Mark Buckler</title>
    <link>http://markbuckler.com/post/</link>
    <description>Recent content in Posts on Mark Buckler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Mark Buckler</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How to Make Bad Deep Learning Hardware</title>
      <link>http://markbuckler.com/post/bad-dnn-asic/</link>
      <pubDate>Wed, 15 Aug 2018 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/bad-dnn-asic/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;ve greatly enjoyed my time as a graduate research intern at
&lt;a href=&#34;http://deepscale.ai/&#34; target=&#34;_blank&#34;&gt;DeepScale&lt;/a&gt; and so I was pleased when &lt;a href=&#34;http://www.forrestiandola.com/&#34; target=&#34;_blank&#34;&gt;Forrest
Iandola&lt;/a&gt; asked me to give a talk to his team on
deep learning hardware. To keep the talk from being a boring list of slides
recounting famous (but dry) neural network hardware papers, we decided to structure it
like one of &lt;a href=&#34;https://en.wikipedia.org/wiki/David_Patterson_(computer_scientist)&#34; target=&#34;_blank&#34;&gt;David
Patterson&lt;/a&gt;&amp;rsquo;s
talks which describe &lt;a href=&#34;https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-123.pdf&#34; target=&#34;_blank&#34;&gt;what &lt;em&gt;not&lt;/em&gt; to
do&lt;/a&gt;. The
talk was well received, so I decided to reformat it into this blog post. This
post does assume some knowledge of DNN processing, but for those of you who are
new to the topic I also provide explanations for each piece of advice in spoiler
tags. If you want to learn more about DNN processing, I recommend this excellent
&lt;a href=&#34;https://arxiv.org/abs/1703.09039&#34; target=&#34;_blank&#34;&gt;survey paper&lt;/a&gt; by &lt;a href=&#34;http://www.rle.mit.edu/eems/people/&#34; target=&#34;_blank&#34;&gt;Vivienne
Sze&lt;/a&gt; and others.&lt;/p&gt;

&lt;p&gt;Fun fact by the way: Forrest and I first met way back in 2007 when our
respective projects made it to the AAAS national high school science fair! The
project I made for that competition developed into &lt;a href=&#34;https://patents.google.com/patent/US8289363B2/en&#34; target=&#34;_blank&#34;&gt;my first
patent&lt;/a&gt; and eventually &lt;a href=&#34;http://firebrandinnovations.com/&#34; target=&#34;_blank&#34;&gt;my
first company&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Before we begin, a few disclaimers. 1) While I have read and written many papers
on DNN hardware design, I have never built DNN hardware in a corporate context.
2) These are my personal opinions and don&amp;rsquo;t reflect those held by DeepScale.&lt;/p&gt;

&lt;p&gt;Alright, lets make some awful hardware!&lt;/p&gt;

&lt;h2 id=&#34;guidelines-for-making-bad-dnn-hardware&#34;&gt;Guidelines for Making Bad DNN Hardware&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Make One Chip To Rule Them All&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Training and inference both need fast access to memory and high parallelism,
so they&amp;rsquo;re pretty much the same thing. This means you can make just one chip
while claiming that your system is highly optimized for all use cases.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    Users interested in training and users interested in inference often
have fundamentally different hardware needs. For example: hardware for training
is generally evaluated on its throughput above all else, while hardware for
inference is typically optimized for latency. Data locality can be different as
well since activations  must be stored for all layers when training but
activations can be discarded during inference. Finally, training hardware will
often need to support much higher precision than inference hardware
due to the need for gradient computation in training. So while some hardware
optimizations improve performance overall, many design decisions will end up
placing your hardware somewhere along a trade-off curve. Without a clear focus
for what your potential users need, you&amp;rsquo;ll find that what you&amp;rsquo;ve built isn&amp;rsquo;t
useful to anyone in particular.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;All DNNs are CNNs&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The most famous DNN paper in recent memory is
&lt;a href=&#34;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&#34; target=&#34;_blank&#34;&gt;AlexNet&lt;/a&gt;.
From this we can conclude that absolutely all neural networks are convolutional
image classifiers. Optimize your system for &lt;code&gt;3x3&lt;/code&gt; (or better yet, &lt;code&gt;5x5&lt;/code&gt;!)
convolutions and then claim that your system is a generic neural network
accelerator.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    CNNs are far from the only kind of neural network. Despite their
popularity in the hardware research community, Google found that CNNs accounted
for &lt;a href=&#34;https://arxiv.org/abs/1704.04760&#34; target=&#34;_blank&#34;&gt;only 5%&lt;/a&gt; of their total DNN workload. The
other big players
include &lt;a href=&#34;https://en.wikipedia.org/wiki/Multilayer_perceptron&#34; target=&#34;_blank&#34;&gt;Multi-Layer Perceptrons&lt;/a&gt; and
&lt;a href=&#34;https://en.wikipedia.org/wiki/Recurrent_neural_network&#34; target=&#34;_blank&#34;&gt;Recurrent Neural Networks&lt;/a&gt; such as
&lt;a href=&#34;https://en.wikipedia.org/wiki/Long_short-term_memory&#34; target=&#34;_blank&#34;&gt;Long Short-Term Memory&lt;/a&gt;
networks. If you plan on making a generic deep learning processor then
optimizing for only CNNs is a huge oversight.&lt;/p&gt;

&lt;p&gt;It is important to point out however that not all hardware must aspire to be
purely generic. After all, part of the reason why the hardware
community has been so interested in CNNs is the many
interesting and effective ways to accelerate them. This includes
&lt;a href=&#34;https://arxiv.org/abs/1803.06312&#34; target=&#34;_blank&#34;&gt;my own work&lt;/a&gt;! Also, while Google servers may
not run CNN inference frequently, vision-heavy applications like self driving cars and
augmented reality rely heavily on CNNs. So, rather than claiming that optimizing
for CNNs is always a bad idea, I simply want to point out that choosing to
specialize for CNN computation must be done intentionally.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Hammer that DRAM&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;GPUs are good at deep learning and have tiny caches, so learn from this by
saving precious area for logic instead of on-chip memory.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    Good computer architects must always be thinking about the spatial and
temporal locality of data in their applications of choice. While many GPU
applications don&amp;rsquo;t have significant temporal locality (hence the reason for
small on-chip memory) this is certainly not the case for deep learning
workloads. As &lt;a href=&#34;https://stanford.edu/~songhan/&#34; target=&#34;_blank&#34;&gt;Song Han&lt;/a&gt; and others point out in
their paper on the &lt;a href=&#34;https://arxiv.org/pdf/1602.01528.pdf&#34; target=&#34;_blank&#34;&gt;Efficient Inference
Engine&lt;/a&gt;: even without changing the
underlying computation, huge amounts of energy and time can be saved by simply
keeping network activations and model parameters on chip.
The &lt;a href=&#34;https://arxiv.org/pdf/1807.11164.pdf&#34; target=&#34;_blank&#34;&gt;ShuffleNet V2&lt;/a&gt; paper also has some
excellent discussion about how memory hierarchy and memory access patterns
impact network performance.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;All DNN Computation is Regular&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Literally all DNN computation is dense matrix multiplication. The regularity
and predictability of this computation means that we can always assume
maximum DRAM bandwidth and there&amp;rsquo;s no need for any hardware or software support
for load balancing.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    As it turns out, lots of DNN computation can be irregular and load
balancing can be a hard problem even with fully regular computation. Irregular
DNN computation be a result of &lt;a href=&#34;https://s3-us-west-2.amazonaws.com/openai-assets/blocksparse/blocksparsepaper.pdf&#34; target=&#34;_blank&#34;&gt;leveraging
sparsity&lt;/a&gt;,
&lt;a href=&#34;https://arxiv.org/abs/1510.00149&#34; target=&#34;_blank&#34;&gt;model compression&lt;/a&gt;, or a variety of other
techniques. Load balancing issues can come from this irregular computation, but
can also come from general scheduling challenges when using systolic arrays
like those in the &lt;a href=&#34;https://arxiv.org/pdf/1704.04760.pdf&#34; target=&#34;_blank&#34;&gt;TPU&lt;/a&gt; or
&lt;a href=&#34;https://people.csail.mit.edu/emer/papers/2016.06.isca.eyeriss_architecture.pdf&#34; target=&#34;_blank&#34;&gt;Eyeriss&lt;/a&gt;.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;NoM NoM NoM&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Clearly the fact that the NoM (Network of the Moment) is so popular now
means that it will always be popular. Ensure that your hardware gets the
most users by fully optimizing your chip for the NoM.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    One of the most fundamental concepts in computer architecture is the
specialization-generalization trade-off. The fully specialized side of this trade-off
would be to take a single algorithm and bake it directly into hardware. This
dramatically improves computational efficiency, but optimizing hardware for a
single algorithm means that the resulting hardware can&amp;rsquo;t do anything other than
compute that algorithm. So, optimizing your hardware for the network of the
moment is a dangerous proposition considering the deluge of papers every year
from NIPS, ICML, ICCV, and CVPR. As an example consider the evolution from
&lt;a href=&#34;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&#34; target=&#34;_blank&#34;&gt;AlexNet&lt;/a&gt;,
to &lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34; target=&#34;_blank&#34;&gt;ResNet&lt;/a&gt;, to
&lt;a href=&#34;https://arxiv.org/abs/1602.07360&#34; target=&#34;_blank&#34;&gt;SqueezeNet&lt;/a&gt;, to
&lt;a href=&#34;https://arxiv.org/abs/1704.04861&#34; target=&#34;_blank&#34;&gt;MobileNet&lt;/a&gt;. The software development cycle
(from idea to implementation) can be around 6 months, while the hardware
development cycle is often closer to 2 years. This means that
overspecialization can lead to your chip being obsolete before it&amp;rsquo;s even built.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;8 Bit Means 8 Bit&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;DNNs are famously well suited for low precision computation, so we only need
to support 8 bit accumulations. Rather than telling anyone that this is what
your hardware does, hide it inside your proprietary DNN framework.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    Computing with 8 bit weights and activations may be one thing, but
accumulating in 8 bits will lead to extreme overflow issues. To begin with,
multiplying two 8 bit numbers together results in a 16 bit product. Additionally
(pun totally intended), many products will be added together as a part of the
multiply accumulate chains inherent to matrix-matrix multiplication. For this
reason, hardware systems must accumulate with precision significantly larger
than that used to store activations and weights. For a more in-depth discussion
of the different kinds of precision and their importance in deep neural
networks I recommend &lt;a href=&#34;http://www.cs.cornell.edu/~cdesa/&#34; target=&#34;_blank&#34;&gt;Chris De Sa&lt;/a&gt;&amp;rsquo;s
paper on &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5789782/&#34; target=&#34;_blank&#34;&gt;low-precision SGD&lt;/a&gt;.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Latency = 1 / Throughput&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Latency is clearly the inverse of throughput, so only report frames per
second with large batch sizes.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    Large batch sizes are often used to increase the temporal locality of
data when training. This significantly reduces the average time needed to
process each frame. For this reason supporting large batch sizes and reporting
performance when using large batch sizes can be completely reasonable. This is
not at all the case for applications which require real-time
inference like self driving cars and augmented reality however. For these applications,
waiting to group multiple frames into a batch is unacceptable since a result is
expected for each frame soon after being received. So, &amp;ldquo;average time per
frame&amp;rdquo; is only equal to real-time latency if the batch size is equal to 1. The
&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2018/03/mi0218_Chung-2018Mar25.pdf&#34; target=&#34;_blank&#34;&gt;Project Brainwave&lt;/a&gt; paper has some great details on this.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Avoid All Complexity&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Exploiting &lt;a href=&#34;https://arxiv.org/abs/1708.04485&#34; target=&#34;_blank&#34;&gt;sparsity&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1602.01528&#34; target=&#34;_blank&#34;&gt;model
compression&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1704.04760&#34; target=&#34;_blank&#34;&gt;systolic
arrays&lt;/a&gt;, or &lt;a href=&#34;https://arxiv.org/abs/1803.06312&#34; target=&#34;_blank&#34;&gt;temporal
redundancy&lt;/a&gt; seems hard. Avoid all this hassle
by telling everyone that you&amp;rsquo;ll support these features but in the end just
do the bare minimum.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    Choosing where your device falls on the specialization-generalization
trade-off curve is a critical decision. You&amp;rsquo;ve already chosen to build hardware
specifically for neural network computation, so go ahead and specialize! Without
any specific optimizations for your application of choice your system will be no
better than a general purpose CPU or GPU.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;The Yield Will Get Better, I Promise&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The device physics folks down the hall can surely scale their experimental
technology to production level soon. CMOS is old news. Its all about graphene,
spintronics, optical computing, or &amp;lt;insert your own post-CMOS tech here&amp;gt;.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    This advice can go for pretty much any kind of computer architecture
research but is especially relevant for deep learning hardware due to its
popularity. Computer architects often get really excited when they find
themselves speaking with device physics people. New computing technologies sound
very promising and have all kinds of desirable properties. The challenge with
nearly all of these new technologies however is scaling the process from tens of
devices per chip to millions or billions of devices per chip. If you are a
process design engineer or a device physics person yourself then by all means do
research in that field, but if you are just a hardware engineer then be wary of
any technology that isn&amp;rsquo;t being used at an industrial scale. Otherwise you&amp;rsquo;ll
find yourself putting bogus numbers in your architectural simulator and/or never
be able to fabricate your chip.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Software? Lame.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Listen, if we wanted to write software we would have joined Facebook. Let&amp;rsquo;s
just have one engineer extend gcc to compile to our instruction set so that we
aren&amp;rsquo;t &lt;em&gt;technically&lt;/em&gt; lying when we say that you can write code for our chip.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;Why is this so bad?&lt;/summary&gt;
    I hope this goes without saying, but hardware is useless without
software support! Hardware designers can get dismissive about software simply
because it isn&amp;rsquo;t their area of expertise but they really shouldn&amp;rsquo;t. With a few
exceptions here and there, even application specific hardware must be
programmed. Any pitch for a new piece of hardware must include both the exciting
new features that the hardware provides as well as an in-depth description of
the software stack used to program the hardware. The features are why someone
might be interested in the hardware and the software stack is how someone might
use the hardware to leverage those great features. Because hardware designers
are the most comfortable with the complexities of their hardware, they should be
actively involved in the development of the software stack for their system.
&lt;/details&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I hope this helps you develop a useless deep learning chip of your very own!
Did I miss any hardware design sins? If you can think of any, feel
free to let me know in the comments below. ðŸ˜„&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>All About Invention Disclosures</title>
      <link>http://markbuckler.com/post/idf/</link>
      <pubDate>Mon, 26 Feb 2018 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/idf/</guid>
      <description>&lt;p&gt;If you&amp;rsquo;ve read my post about
&lt;a href=&#34;http://www.markbuckler.com/post/patenting/&#34; target=&#34;_blank&#34;&gt;patenting in academia and industry&lt;/a&gt;
then you know why you might want to file a patent with your university or
company. The first step to filing a patent in most organizations (after creating
the invention of course!) is filling out an Invention Disclosure Form or IDF.
These forms will be created, provided by, and reviewed by your organization&amp;rsquo;s
technology transfer office or center for technology licensing. While IDFs tend
to differ between organizations they are all intended as a way for the inventor
to communicate to the organization how a new invention works and why it is
worth patenting. If the result of the organization&amp;rsquo;s review is that the
invention should be patented then in-person meetings with patent attorneys will
be arranged to discuss in more detail.&lt;/p&gt;

&lt;p&gt;This post is written as a guide for those of you who might be filling out your
first IDF. This may also be helpful to any of you who are creating the first
standard disclosure form for your organization. I&amp;rsquo;ll describe some common
questions in IDFs and strategies for answering these questions well. As I say in
my &lt;a href=&#34;http://www.markbuckler.com/post/patenting/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, I am not a
patent attorney so please don&amp;rsquo;t take any of what I say here as legal advice!&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Who are the inventors?&lt;/p&gt;

&lt;p&gt;In some cases the answer to this question will be very straightforward.
Perhaps you were the only person on the project in which you created the
invention and you never discussed the invention with others. Most of the time,
however, people collaborate. If your invention was made in a project with other
people then the determination of who may or may not be considered an inventor is
a matter of discussion.&lt;/p&gt;

&lt;p&gt;While &lt;em&gt;authorship&lt;/em&gt; on papers is generally given to people who have made
important contributions when building prototypes, performing testing, and
writing text for the paper, &lt;em&gt;inventorship&lt;/em&gt; is legally different. Patent law
defines an inventor of a patentable invention as someone who conceives of an
original, useful, and non-obvious idea. This can but does not necessarily
include students, professors, your boss, your employees, and other
collaborators. Use your best judgement and ask all collaborators who you believe
may have contributed to the idea considered in the invention disclosure. Only
after everyone agrees will the inventor list be settled. Keep in mind that who
gets to claim inventorship should not be based on charity, flattery, or spite.
Patents can and have been invalidated for an incorrect list of inventors. For
more information about this topic, see
&lt;a href=&#34;https://otl.stanford.edu/documents/who_is_inv.pdf&#34; target=&#34;_blank&#34;&gt;this helpful PDF&lt;/a&gt;
provided by Stanford&amp;rsquo;s Office of Technology Licensing.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What problem does the invention solve?&lt;/p&gt;

&lt;p&gt;For an invention to be useful and therefore worthy of patent protection, it
must solve some problem that exists in the world. If you are used to writing
research papers, you can think of this like the &lt;em&gt;motivation&lt;/em&gt; section in a
paper. Because the patent lawyers and other people reviewing this IDF won&amp;rsquo;t
necessarily be experts in your field make sure to include any scientific or
technical background that might be needed to understand why the invention is
useful and how it may work. This is similar to the &lt;em&gt;background&lt;/em&gt; section in a
paper.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What prior art are you aware of?&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Prior art&amp;rdquo; simply refers to any patents, papers, documentation, or other
published information that you are aware of which is related to your invention.
This is similar to the &lt;em&gt;related work&lt;/em&gt; section in a research paper. If there is a
very large body of work in your field then try to focus on citing survey papers
for the general background and then limit your more specific citations to work
which is closely related. Also, do your best to list any other groups,
researchers, or companies who work in your area as it will help the attorneys
in their further prior art search.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What competitors are you aware of?&lt;/p&gt;

&lt;p&gt;Here you list any competing products or inventions that you&amp;rsquo;re aware of.
Stress the flaws or drawbacks of each of your competitors so that you can more
easily demonstrate your advantage. If there aren&amp;rsquo;t yet any true solutions to the
problem that your invention solves then list any workarounds that you
might be aware of.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What are the unique features of the invention?&lt;/p&gt;

&lt;p&gt;Here you describe your invention&amp;rsquo;s competitive advantage and which
specific elements of your invention are novel. You can think about this like the
&lt;em&gt;contributions&lt;/em&gt; section in a paper. Try to focus both on why you are different
from the competition and why this difference results in a superior product or
method. Use your best sales skills!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How does the invention work?&lt;/p&gt;

&lt;p&gt;This is often the most complex section of the IDF. Use pictures and visual
aids whenever possible. You could also consider including a glossary with
definitions of the jargon used throughout the IDF. Keep in mind that the readers
may not be as familiar with your subject area as you are. Technology offices try
to match inventions as closely to experts as possible, but some disciplines can
be very broad and others very specialized.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Are there any alternative versions of the invention?&lt;/p&gt;

&lt;p&gt;In engineering we often need to make design decisions to optimize the
performance of our design or simplify the design process. Your final prototype
represents only one possible choice for each design decision. To prevent someone
from designing around your patent by making an insignificantly different choice
in their design, your patent attorney will try to make the claims of your patent
as general as possible. You can help your attorney by describing not just the
specifics of your tested prototype, but also the entire possible design space.
This can include variations that you haven&amp;rsquo;t tested, or even variations that you
have tested and have determined to be inferior to your final prototype.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How could the invention be used?&lt;/p&gt;

&lt;p&gt;Here you lay out all possible use cases for your invention. Ease of use is
important in evaluating the value of a potential patent. Overly onerous
inventions may not be worth the benefit they provide. If possible, provide
examples of other products or inventions with similar use cases. In a similar
spirit to listing alternative versions of your invention, get creative and try
to think of alternative uses for your invention as well. Alternative uses for
your work may make it more valuable and enable broader claims.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How can the use of this invention be detected?&lt;/p&gt;

&lt;p&gt;As I discuss in my post on
&lt;a href=&#34;http://www.markbuckler.com/post/patenting/&#34; target=&#34;_blank&#34;&gt;patenting in academia and industry&lt;/a&gt;,
part of a patent&amp;rsquo;s value is how easy it is to detect when the invention is
being used without permission. Without the ability to detect the use of the
invention, the patent can&amp;rsquo;t be enforced and is therefore useless. Your patent
attorney may be more familiar with common methods for detecting use in your
field since this isn&amp;rsquo;t a common thought for researchers, but list whatever
methods you are aware of.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Who might want to purchase or license the potential patent?&lt;/p&gt;

&lt;p&gt;This question is most relevant in academia where the assumption is not that
the patent will be used directly by your organization. Universities don&amp;rsquo;t make
products, and so a patent only has value if there is a demand for it! To answer
this question list any people or organizations who might be interested in buying
or licensing the potential patent from your organization. This can include the
most prominent companies in your field as well as any any startups you may be
aware of. Some technology offices may even begin marketing your idea before
deciding to patent your invention as a way of determining demand, so give them
as much help as you can.&lt;/p&gt;

&lt;p&gt;If you are in a university and hope to launch a company using this patent,
be extremely up front about your goals. You may even want to contact the
technology licencing office before submitting an IDF to explain your intentions.
Without knowing your goals the technology licencing office may sell the patent
to an outside party without ever consulting you. Even simply marketing your
invention before it has been patented may prevent you from creating a stealth
mode startup. Make sure to communicate often and effectively with your
university&amp;rsquo;s office to avoid such an issue. Your business plan may be a part of
convincing the office to license to you instead of a large company, so prepare
your business plan as early as possible.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After answering these 10 questions you will have successfully filled out your
first IDF. Congratulations!  As you can see, a great deal of the questions asked
in an IDF are similar to material that you may have already prepared for a
technical report or research publication. Feel free to directly copy and paste
from previous writing that you&amp;rsquo;ve done, and attach the original document to your
IDF for ease of reading. With any luck your organization will be interested in
filing a patent on your invention. May lots of patent filing bonuses or
licencing revenue flow your way!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Patenting in Academia and Industry</title>
      <link>http://markbuckler.com/post/patenting/</link>
      <pubDate>Sat, 24 Feb 2018 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/patenting/</guid>
      <description>&lt;p&gt;We all get excited about doing scientific or engineering research for different
reasons, but most of us seek the thrill of creating something entirely new.
In this way, research can be just as wonderful as the creative arts. Publishing
your new ideas is great for sharing information with the world, but sometimes
you want to sell your ideas too. This is where filing for a patent can be very
useful. I have some experience in this area as I have patented inventions
&lt;a href=&#34;http://patents.google.com/patent/US8289363B2&#34; target=&#34;_blank&#34;&gt;on my own&lt;/a&gt;,
in &lt;a href=&#34;https://patents.google.com/patent/US9344099B2&#34; target=&#34;_blank&#34;&gt;industry&lt;/a&gt;,
and most recently in academia.&lt;/p&gt;

&lt;p&gt;Because I can&amp;rsquo;t cover the entire topic of
&lt;a href=&#34;https://en.wikipedia.org/wiki/Intellectual_property&#34; target=&#34;_blank&#34;&gt;Intellectual Property (IP) law&lt;/a&gt;
in a single blog post, I will choose instead to answer questions that someone
might have if they were interested in patenting at a company or university. I
hope other researchers and inventors like myself will find this information
useful. Also, I am not a patent attorney, so please don&amp;rsquo;t take anything that I
say here as legal advice!&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What is a patent?&lt;/p&gt;

&lt;p&gt;In case you don&amp;rsquo;t already know, a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Patent&#34; target=&#34;_blank&#34;&gt;patent&lt;/a&gt; on a specific idea gives
exclusive usage rights of that idea to whoever holds the patent. In theory, this
means that the patent holder can prevent others from using the idea. The person
who creates the invention is referred to as the &lt;em&gt;inventor&lt;/em&gt;, and the person or
organization who holds the patent is the &lt;em&gt;assignee&lt;/em&gt;. A patent can be used to
make money in a number of ways:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Making and selling products or services with the patented idea&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Selling the patent to another organization&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Licensing out the patent in exchange for a percentage of sales&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Suing for the profits made by an organization who used the patented ideas
without your permission&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What can be patented?&lt;/p&gt;

&lt;p&gt;While patenting restrictions vary between countries and over time,
most countries agree that a patentable idea must have all of the following
properties:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Non-abstract&lt;/p&gt;

&lt;p&gt;Mathematical formulas and pure algorithms may be amazing, but these
abstract ideas are not considered to be patentable. Which ideas are
abstract can be controversial, and so there are many examples of courts
&lt;a href=&#34;https://www.theiplawblog.com/2017/03/articles/patent-law/more-patent-invalidated-as-abstract-ideas/&#34; target=&#34;_blank&#34;&gt;invalidating patents after they were issued&lt;/a&gt;
due to disagreements on this issue.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Man-made&lt;/p&gt;

&lt;p&gt;Natural laws and natural phenomena are also not patentable. One of the
most prominent examples of a patent portfolio being invalidated for being
natural is the case against Myriad Genetics who previously held a patent on
&lt;a href=&#34;https://en.wikipedia.org/wiki/Myriad_Genetics#Controversies&#34; target=&#34;_blank&#34;&gt;breast cancer genes&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Novel&lt;/p&gt;

&lt;p&gt;Similar to a publication in a research conference or journal, patentable
ideas must be significantly different from what has been published in the past.
Academics usually refer to existing publications as &amp;ldquo;related work&amp;rdquo;, while patent
attorneys refer to them as &amp;ldquo;prior art&amp;rdquo;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Useful&lt;/p&gt;

&lt;p&gt;This is by far the easiest requirement to meet. All that you need to
demonstrate is that your idea successfully accomplishes some goal. That goal
need not be considered useful by a majority of people, it just needs to be
possible and legal. There are all kinds of hilarious
&lt;a href=&#34;https://www.oddee.com/item_96675.aspx&#34; target=&#34;_blank&#34;&gt;patents with dubious usefulness&lt;/a&gt;
that got approved by the US patent office.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Non-obvious&lt;/p&gt;

&lt;p&gt;Every field of engineering and design has a certain set of common
knowledge that an expert in the field would be familiar with. If such an expert
would find an idea to be obvious or common knowledge, then that idea is
considered to be &amp;ldquo;obvious&amp;rdquo;. This is often a subjective judgement, so
&lt;a href=&#34;http://www.ipwatchdog.com/2014/02/01/when-is-an-invention-obvious/id=47709/&#34; target=&#34;_blank&#34;&gt;see here&lt;/a&gt;
for further discussion.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Why should I bother patenting if I&amp;rsquo;m not the assignee?&lt;/p&gt;

&lt;p&gt;Most companies and universities require that you sign some form of a
Confidential Information and Inventions Assignment Agreement (CIIAA) before you
join them. The specifics of each CIIAA vary, but most force you to
give your assignee rights to your employer for all inventions that you create
while employed by them. This means that if you invent something new while
employed, only your employer can file for a patent on this invention. It is
important to remember however that your employer still needs you to perform your
duties as inventor (disclosing your invention and explaining how it works to the
attorneys), so companies and universities usually provide inventor incentives.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Incentives in industry&lt;/p&gt;

&lt;p&gt;First of all, while you do give up your assignee rights while employed
you never give up your inventorship. This means that if you file a patent with
your organization then you will still get credit for creating the idea even if
you don&amp;rsquo;t own it. This can be a great option to get your name out there if your
organization prohibits publishing but encourages patenting. Second, companies
will often provide cash bonuses to you if your invention disclosure gets
approved for filing and/or if a patent is issued for an invention of yours.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Incentives in academia&lt;/p&gt;

&lt;p&gt;Beyond being self employed or in a startup incubator, academia is the
best work environment to build intellectual property in. A university&amp;rsquo;s goal is
to launch your career rather than make large profits, and as such they usually
give you some amount of profits from and control over your inventions. While
every research university is different, it is not uncommon for there to be a
preference to licence patents to inventors themselves if they choose to start a
company. Most universities also give a share of any profits to the inventors.
For example,
&lt;a href=&#34;http://www.ctl.cornell.edu/inventors/marketing-inventions.php&#34; target=&#34;_blank&#34;&gt;Cornell allocates a third of patent profits&lt;/a&gt;
to the inventor(s).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Can I patent on my own?&lt;/p&gt;

&lt;p&gt;As long as you aren&amp;rsquo;t under a CIIAA then yes, you can patent on your own.
Fees from the patent office will be reduced because you as a person are a
&lt;a href=&#34;https://www.uspto.gov/learning-and-resources/newsletter/inventors-eye/new-fees-and-micro-entity-status-take-effect-march&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;micro entity&amp;rdquo;&lt;/a&gt;,
but the cost of hiring a skilled patent attorney may be significant. The best
bet for individual inventors (and sometimes even organizations) is to first file
for a provisional patent application.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Should I file a provisional patent application?&lt;/p&gt;

&lt;p&gt;A provisional patent application will not be reviewed by the patent office
and will not become a patent without further applications, but it serves the all
important function of setting the filing date. A lot of work goes into building
the claims in a formal patent application, and so the provisional application
provides a way to set the date of filing before time has been spent on
developing claims. Even skilled patent attorneys will often suggest filing a
provisional patent application before continuing to the claims. Provisional
applications are also very low cost as their fees are much smaller than that of
a full application. This makes them a good option for individual or small patent
applicants who haven&amp;rsquo;t yet raised funds for a patent attorney. Keep in mind
though that a provisional application only holds power for a year unless a full
patent application has been filed in that time.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When should I file?&lt;/p&gt;

&lt;p&gt;In a phrase: As Soon As Possible. You might remember being told in school
that you should date every single entry in your lab/design notebook. That was
because at the time (pre-2013) the US had a &amp;ldquo;first-to-invent&amp;rdquo; patenting system.
If someone else was to file for a patent that you had invented first (as proven
by your dated lab notebook), the other person&amp;rsquo;s patent would be invalidated.
This is no longer the case however as the US has
&lt;a href=&#34;https://en.wikipedia.org/wiki/First_to_file_and_first_to_invent#USA_change_to_first-inventor-to-file_(FITF)&#34; target=&#34;_blank&#34;&gt;changed to &amp;ldquo;first-inventor-to-file&amp;rdquo;&lt;/a&gt;.
With this in mind, if you want to patent an invention in the US or any other
&amp;ldquo;first-to-file&amp;rdquo; country you must file as soon after creating the invention as
possible to prevent others from filing before you.&lt;/p&gt;

&lt;p&gt;Another consideration is when to patent in relationship to publishing. In a
university your main priority as a researcher is usually to publish your work.
Some may think that this precludes you from patenting your work as well, but
this isn&amp;rsquo;t true! While some countries do prevent you from patenting after
publishing your work, the US allows a one-year grace period. A much better
strategy of course is to file a patent application before you publish.
Thankfully, most conferences and journals enforce confidentiality on
submissions, meaning that simply submitting your work for publication doesn&amp;rsquo;t
count as publication. So, if you verify that your publication venue supports
submission confidentiality then you can begin filing for your patent immediately
after finishing your submission.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Is my invention better protected as a patent or trade secret?&lt;/p&gt;

&lt;p&gt;Before patenting, there was very little monetary incentive to publish new
inventions. Keeping your inventions a secret ensured that no one else could use
them. If no one is sharing ideas then it is very hard for a society to progress
technologically. Patenting was proposed as a bargain with inventors: publish
exactly how your inventions work in exchange for the right to prevent others
from using those inventions for a set time period.&lt;/p&gt;

&lt;p&gt;While patenting makes sense in theory, there have been
&lt;a href=&#34;https://www.youtube.com/watch?v=3bxcc3SM_KA&#34; target=&#34;_blank&#34;&gt;many issues&lt;/a&gt;
with our implementation of the system. One such issue is that it can be quite
hard to prove that someone is using your invention. Closed source software is a
perfect example of this as the actual written code is obfuscated by the
compilation process. Without the ability to prove that someone is violating your
patent, the patent is useless. Also, publishing your invention via the patenting
process could provide others with enough information to design around you. Your
patent attorney will try to make your patent&amp;rsquo;s claims as general as possible,
but clever engineers may be able to create a new system without violating your
claims that still gets the same benefit. So, before patenting your invention
consider that your competitors may either hide their use of your patent or
circumvent it through clever design.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Is there such a thing as an international patent?&lt;/p&gt;

&lt;p&gt;Nope! At least at the time of writing there is no such thing as an
international patent or patent office. There is however an International Patent
Cooperation Union which facilitates a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Patent_Cooperation_Treaty&#34; target=&#34;_blank&#34;&gt;single patent filing system&lt;/a&gt;
for all member countries. While no patent is granted through such an
application, it does provide a unified system for filing dates and applicants
are provided with some written opinions about the patentability of the
invention.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Invention Disclosure Form (IDF)&lt;/p&gt;

&lt;p&gt;Lets say that after reading all of this you are convinced that you have a
great invention that would be well protected by a patent. Congratulations! If
you are in a company or university your next step is to fill out and submit an
Invention Disclosure Form. This process can be complex in and of itself, and so
I have written about it in its own separate blog post.
&lt;a href=&#34;http://www.markbuckler.com/post/idf/&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;
if you&amp;rsquo;d like to read on!&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Cutting Videos with FFmpeg</title>
      <link>http://markbuckler.com/post/cutting-ffmpeg/</link>
      <pubDate>Thu, 06 Jul 2017 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/cutting-ffmpeg/</guid>
      <description>&lt;p&gt;While building the &lt;a href=&#34;https://github.com/mbuckler/youtube-bb&#34; target=&#34;_blank&#34;&gt;downloading and decoding
scripts&lt;/a&gt; for the &lt;a href=&#34;https://research.google.com/youtube-bb/index.html&#34; target=&#34;_blank&#34;&gt;Youtube BoundingBoxes
dataset&lt;/a&gt; I needed to
accurately cut videos into smaller clips. Some of the annotated videos were
quite long and the annotations rarely covered the full video, so to save space
my scripts cut out and save only the annotated sections. If done incorrectly
this video cutting can cause subtle frame timing issues which I didn&amp;rsquo;t fully
understand when I started writing these scripts. If you want to avoid these
problems read below for the proper way to accurately cut videos with
&lt;a href=&#34;http://ffmpeg.org/&#34; target=&#34;_blank&#34;&gt;FFmpeg&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First, a very quick review of video compression. Most modern video compression
algorithms use a technique called &lt;a href=&#34;https://en.wikipedia.org/wiki/Motion_compensation&#34; target=&#34;_blank&#34;&gt;motion
compensation&lt;/a&gt; to reduce the
size of stored video files. All frames in MPEG are stored as either Key frames
(I frames) or Predicted frames (P or B frames). Each Key frame is compressed
with some variation on the &lt;a href=&#34;https://en.wikipedia.org/wiki/JPEG&#34; target=&#34;_blank&#34;&gt;JPEG compression
codec&lt;/a&gt;, but Predicted frames are represented
as motion compensated versions of earlier frames (as in P frames) or both
earlier and later frames (as in B frames). Because these motion compensation
references take up much less space than a compressed JPEG, overall the
compressed video takes up less space. For (much) more detail you can see &lt;a href=&#34;https://users.cs.cf.ac.uk/Dave.Marshall/Multimedia/node255.html&#34; target=&#34;_blank&#34;&gt;Dave
Marshall&amp;rsquo;s excellent
explanation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now that we&amp;rsquo;ve reviewed video compression and the different kinds of encoded
frames, we can talk about seeking. Seeking is the process used to find certain
sections of the video to either extract a frame or cut out a portion. FFmpeg has
implemented a few options for our use, but their differences in behavior and/or
usage can be easy to overlook. Here we will discuss the three methods of seeking
(and by extension cutting) video with FFmpeg, with each corresponding to a point
on the speed/accuracy tradeoff.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Key Frame Seeking&lt;/p&gt;

&lt;p&gt;The fastest way to extract a portion of video from a larger video (with a 60
second clip starting 30 seconds in) would be the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ffmpeg -ss 30 -i input_vid.mp4 -t 60 -c copy output_clip.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This method is so fast because it uses Key frames when performing seek, and
there are far fewer Key frames than Predicted frames. It also is a &lt;a href=&#34;https://ffmpeg.org/ffmpeg.html#Stream-copy&#34; target=&#34;_blank&#34;&gt;stream
copy&lt;/a&gt; meaning that the encoded data
extracted from the original video is taken directly without decoding and then
re-encoding. While this feature may be useful for some users who don&amp;rsquo;t care
about frame accuracy, it doesn&amp;rsquo;t work for our purposes. This is because even
though FFmpeg 2.1 enabled frame accurate Key frame seeking for frame extraction
(&lt;a href=&#34;https://trac.ffmpeg.org/wiki/Seeking&#34; target=&#34;_blank&#34;&gt;more detail here&lt;/a&gt;) this behavior is not
supported in FFmpeg 2.6 when cutting out clips of video. This means that the
start of your video will be aligned with the nearest Key frame to 30 seconds,
not the nearest frame independent of encoding format.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;All-Frame Seeking&lt;/p&gt;

&lt;p&gt;A slightly slower and more accurate method of video cutting would be the
following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ffmpeg -i input_vid.mp4 -ss 30 -t 60 -c copy output_clip.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Can you tell the difference? It is frustratingly similar to the previous
command&amp;hellip; It turns out that FFmpeg arguments are order sensitive, so choosing
the clip&amp;rsquo;s start time after the input video causes a change in behavior! This
method uses all-frame seeking, also known as &lt;a href=&#34;https://trac.ffmpeg.org/wiki/Seeking#Outputseeking&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;output
seeking&amp;rdquo;&lt;/a&gt; by FFmpeg users.
It is also a stream copy, but considers all frames (including Predicted frames)
when performing a seek. This means that your output clip will start with the nearest frame
to 30 seconds even if it is a predicted frame.&lt;/p&gt;

&lt;p&gt;If you use this command and try to play your output clip, you may notice that
the clip starts frozen, or with black frames in the beginning. Did FFmpeg do
something wrong? No, that behavior is simply a result of the functionality that
we requested when we performed an all-frame seek on a stream copy. If your 30
second start happens to align with a Predicted frame, that Predicted frame will
be copied into the output clip, along with the rest of the frames in the 60
second portion. But as we already established, Predicted frames are simply
motion compensated references to previous or following Key frames. By stream
copying with all-frame seeking we have removed the reference Key frames which
came before our first frame. This is why your video player displays frozen or
black frames: the necessary data to represent the first portion of your
video isn&amp;rsquo;t included in the file.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Full Re-Encoding&lt;/p&gt;

&lt;p&gt;So Key frame seeking causes missalignment and All-frame seeking causes broken
frames, is there another option? Yes, but some folks don&amp;rsquo;t like it. Instead of
performing a stream copy we can decode the source video, and then re-encode the
output clip:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ffmpeg -i input_vid.mp4 -ss 30 -strict -2 -t 60 output_clip.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This isn&amp;rsquo;t perfect for two reasons: 1) Re-encoding can cause
quality loss if done incorrectly, and 2) Re-encoding is far slower than stream
copying. While both of these two points should be considered, if you want to
copy a frame-exact section of video you have to re-encode. At least now you
know!&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>My Old Electronic Music Blog</title>
      <link>http://markbuckler.com/post/quoth_the_raver/</link>
      <pubDate>Tue, 02 May 2017 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/quoth_the_raver/</guid>
      <description>&lt;p&gt;Back in 2010 I started a blog dedicated to electronic music called Quoth
the Raver (a play on Quoth the Raven). It was a huge amount of fun
sharing the music I found with everyone on the site, and it inspired me
to get even more familiar with the various genres, artists, and labels.
These days electronic music (also known as EDM) has exploded in
popularity, so the novelty of sharing new artists has worn off to a
certain extent. For this reason I haven&amp;rsquo;t updated the blog in quite a
long time, but I did recently go through to fix up some broken components
for archiving the site.&lt;/p&gt;

&lt;p&gt;If anyone is curious to see what I was listening to and raving about
back then feel free to &lt;a href=&#34;https://quoththeraverarchive.wordpress.com/&#34; target=&#34;_blank&#34;&gt;check out the
website!&lt;/a&gt; If you&amp;rsquo;re more
interested in what I&amp;rsquo;m listening to these days, go ahead and check out
what I love on &lt;a href=&#34;https://soundcloud.com/quoththeraver&#34; target=&#34;_blank&#34;&gt;SoundCloud&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://markbuckler.com/img/quoth_the_raver.jpg&#34; alt=&#34;Quoth the Raver&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing LaTeX in Vim</title>
      <link>http://markbuckler.com/post/latex-in-vim/</link>
      <pubDate>Mon, 03 Apr 2017 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/latex-in-vim/</guid>
      <description>&lt;p&gt;As an academic I am often writing LaTeX code for publications or general
documentation. I used to use &lt;a href=&#34;https://www.sharelatex.com/&#34; target=&#34;_blank&#34;&gt;ShareLatex&lt;/a&gt;
and &lt;a href=&#34;https://www.overleaf.com/&#34; target=&#34;_blank&#34;&gt;Overleaf&lt;/a&gt; because I have a secret love
of GUIs (Lord forgive me!), but recently my co-authors have prefered
to work in LaTeX repos shared on &lt;a href=&#34;https://github.com/&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;. For
this reason my most recent paper was actually written entirely in Vim!
This post isn&amp;rsquo;t meant to be a complete description of the best way to
edit LaTeX in Vim, but instead I want to
share some of the tools, tricks, and tips that I&amp;rsquo;ve
found useful when writing LaTeX in Vim.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Vim environment setup&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve made a nice little &lt;a href=&#34;https://github.com/mbuckler/vim-config&#34; target=&#34;_blank&#34;&gt;GitHub
repo&lt;/a&gt; to host my Vim
configuration settings (.vimrc) so that porting it between my machines
is made easier. No need to copy my .vimrc wholesale if you don&amp;rsquo;t like
everything, but these are a few options that I use:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Installing &lt;a href=&#34;https://github.com/VundleVim/Vundle.vim&#34; target=&#34;_blank&#34;&gt;Vundle&lt;/a&gt; for Vim
package management and &lt;a href=&#34;https://github.com/tpope/vim-sensible&#34; target=&#34;_blank&#34;&gt;sensible.vim&lt;/a&gt;
for near-universal improvements to the default Vim settings.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tabs vs spaces&amp;hellip; We could &lt;a href=&#34;https://www.youtube.com/watch?v=SsoOG6ZeyUI&#34; target=&#34;_blank&#34;&gt;fight all
day&lt;/a&gt; about using tabs or
spaces, but you&amp;rsquo;ll want to put your preferred settings in your .vimrc.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Automatic text wrapping with &lt;code&gt;set wrap&lt;/code&gt;. This is one of the most
useful settings when writing LaTeX in Vim.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Change out that ugly red column border with a nice grey column border
with &lt;code&gt;set colorcolumn=+1&lt;/code&gt; and &lt;code&gt;hi ColorColumn ctermbg=7&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Show line numbers for easy reference: &lt;code&gt;set number&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Set your preferred spell check default. As an American I do &lt;code&gt;set
spelllang=en_us&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Useful Vim commands&lt;/p&gt;

&lt;p&gt;In addition to having a good setup for Vim, here are a few commands that
I am constantly using.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Search: &lt;code&gt;/foo&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Search and replace: &lt;code&gt;:%s/foo/bar/g&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Toggle line numbers: &lt;code&gt;set nu&lt;/code&gt;, &lt;code&gt;set nu!&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Enable pasting without auto-indentation: &lt;code&gt;set paste&lt;/code&gt;, &lt;code&gt;set paste!&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Turn on and off spell checking: &lt;code&gt;set spell&lt;/code&gt;, &lt;code&gt;set spell!&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Automatically wrap a block of text: First select with &lt;code&gt;v&lt;/code&gt; for
visual, and then use &lt;code&gt;gq&lt;/code&gt; to perform the wrapping.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Indent an entire section: First select with &lt;code&gt;v&lt;/code&gt; and then indent
with &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Automatic LaTeX compilation&lt;/p&gt;

&lt;p&gt;This isn&amp;rsquo;t Vim specific, but you&amp;rsquo;re going to need a
complation method to turn your LaTeX in to a PDF. On Ubuntu this works
very well for me:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Install texlive and latexmk from your package manager. This will require more
than a Gigabyte of space on your disk and so will take a while, but that
sure beats having to selectively install LaTeX packages.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install texlive-full latexmk
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Start a background process to automatically compile your LaTeX and
generate a PDF. You can edit your document in a separate terminal tab
and have the PDF on the other side of your screen. Seemless editing!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;latexmk -pvc -pdf main.tex &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Developing in Docker</title>
      <link>http://markbuckler.com/post/docker-use/</link>
      <pubDate>Sun, 02 Apr 2017 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/docker-use/</guid>
      <description>&lt;p&gt;Most of us academic/industrial ECE/CS researchers want to make our
results as reproducible as possible. Its good for the integrity of our
field and it also helps future researchers and developers to build on
our prior work. &lt;a href=&#34;https://github.com/&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; is great for distributing
software, but code can rarely be compiled and run on its own as nearly
all modern software relies heavily on packages and dependencies.
Installing these dependencies can be incredibly frustrating or possibly
even impossible depending on how long ago the code was written.
Thankfully, &lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; is here to save the day!&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What benefits does Docker provide?&lt;/p&gt;

&lt;p&gt;Running code or even product deployment without ever installing
dependencies, enabling multiple dependency versions on a server without
conflicts, &amp;ldquo;pulling&amp;rdquo; of environments from &lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34;&gt;Docker
Hub&lt;/a&gt; as simply and easily as cloning a GitHub
repository, and all without noticeable performance degradation.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How does Docker provide all of this modularity and portability?&lt;/p&gt;

&lt;p&gt;By very nearly being a Virtual Machine (VM) but not going the full way.
&lt;a href=&#34;https://docs.docker.com/get-started/#containers-vs-virtual-machines&#34; target=&#34;_blank&#34;&gt;See here for more
details&lt;/a&gt;,
but rather than implementing an entire OS as a VM might do, an
instantiation of a Docker image (called a &amp;ldquo;Container&amp;rdquo;) only implements
binaries, libraries, and applications. This makes running a Windows
image on Linux or vice versa tricky since they don&amp;rsquo;t have the same
kernel, but since most of the folks I know develop on Linux this hasn&amp;rsquo;t
been a problem for me. In case you&amp;rsquo;re interested in running Docker on
macOS or Windows check out &lt;a href=&#34;http://containerjournal.com/2016/08/15/docker-not-just-linux-anymore/&#34; target=&#34;_blank&#34;&gt;this blog
post&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;From a practical standpoint, how do I use Docker?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://markbuckler.com/img/docker_high_level.png&#34; alt=&#34;Docker at a high level&#34; /&gt;&lt;/p&gt;

&lt;p&gt;First, write an installation script for all of your dependencies. This
script is written with Docker specific syntax and is called a
Dockerfile. Then, run these commands to build a Docker image of your
environment by using &lt;code&gt;docker build&lt;/code&gt;. Once successfully built, you can
instantiate copies of this image as many times as you would like by
using &lt;code&gt;docker run&lt;/code&gt; to create Docker containers. It is in these
containers that you will run or develop your code. If you would like
other people to be able to use your Docker image you can push to
DockerHub (with &lt;code&gt;docker push&lt;/code&gt;), and if you want to use someone else&amp;rsquo;s
image you can pull from DockerHub (with &lt;code&gt;docker pull&lt;/code&gt;).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How do I write a Dockerfile?&lt;/p&gt;

&lt;p&gt;You can check out the &lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34; target=&#34;_blank&#34;&gt;full reference&lt;/a&gt;, but here is
a simple example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Start with an existing Docker image to give yourself a head start
FROM ubuntu:14.04

# Change to a given directory
WORKDIR /root

# Run some shell commands to install dependencies
RUN apt-get update &amp;amp;&amp;amp; apt-get upgrade &amp;amp;&amp;amp; apt-get install -y \
    build-essential \
    git \
    etc...

# Clone and build code not available through your package manager
RUN git clone https://github.com/halide/Halide.git
WORKDIR /root/Halide
RUN make -j8

# Set any necessary environment variables
ENV LD_LIBRARY_PATH /root/Halide/bin:$LD_LIBRARY_PATH

# Lastly, set your workdir to be your default when starting the image
WORKDIR /root
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How do I run a Docker image (create a docker container)?&lt;/p&gt;

&lt;p&gt;First, pull the image you&amp;rsquo;d like to use or build one from a Dockerfile
like the one shown above.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull mbuckler/approx-vision
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, use the docker run command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run \
-v &amp;lt;path to datasets&amp;gt;:/datasets \
-v &amp;lt;path to approx-vision&amp;gt;:/approx-vision \
-it mbuckler/approx-vision \
/bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the example command above you see that I start with &lt;code&gt;docker run&lt;/code&gt;, and
then create two &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockervolumes/&#34; target=&#34;_blank&#34;&gt;docker
volumes&lt;/a&gt;. These
volumes allow me to interact with data outside of the docker container.
Then I choose which image to run, and start myself off with a bash
shell.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What if I want to use my GPU from within a Docker container?&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;re in luck! NVIDIA provides
&lt;a href=&#34;https://github.com/NVIDIA/nvidia-docker&#34; target=&#34;_blank&#34;&gt;nvidia-docker&lt;/a&gt;, a specific
application for linking NVIDIA GPU&amp;rsquo;s and docker.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What if I want to use X forwarding from within a Docker container?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://people.ece.cornell.edu/skand/&#34; target=&#34;_blank&#34;&gt;Skand Hurkat&lt;/a&gt; and I figured
out a great way to do this. He&amp;rsquo;s posted the instructions
&lt;a href=&#34;https://people.ece.cornell.edu/skand/post/x-forwarding-on-docker/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;,
but I&amp;rsquo;ll cross-post them here for completeness.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Include the X packages within your Docker image by adding these
commands to your Dockerfile.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN apt-get update
RUN apt-get install -qqy x11-apps
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Set the path to your &lt;code&gt;.Xauthority&lt;/code&gt; file. Your &lt;code&gt;.Xauthority&lt;/code&gt; file
will automatically be created in your home directory if using X11
forwarding on a server you&amp;rsquo;re accessing remotely, but if you&amp;rsquo;re using
Docker on your local device then you&amp;rsquo;ll need to create the file with
touch.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;XAUTH=$HOME/.Xauthority
touch $XAUTH
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Run your Docker image. Use the host&amp;rsquo;s networking stack and
connect both the display and Xauthority environment variables.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --network=host --env DISPLAY=$DISPLAY -v $XAUTH:/root/.Xauthority -it &amp;lt;dockerimagename&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OK Docker fanboy, tell me the downsides&amp;hellip;&lt;/p&gt;

&lt;p&gt;For one, creating/pulling lots of Docker images can take up a lot of
disk space. The real downside however is that Docker users have sudo
privileges on the local machine when running containers. You can find a
really excellent blog post about this
&lt;a href=&#34;https://fosterelli.co/privilege-escalation-via-docker.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, but
at the end of the day you have two choices:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Require that users invoke sudo when executing docker commands.&lt;/p&gt;

&lt;p&gt;This isn&amp;rsquo;t super attractive since it makes usage less convenient,
but it is the safest option.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create and use a docker group.&lt;/p&gt;

&lt;p&gt;With this option anyone who is in the docker group can run docker
commands without sudo. This is the option I use, where I only add users to the docker
group that I would consider adding to the sudo group. I also inform new
users about the dangers, as you can do a lot of damage by mounting
sensitive volumes.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>How to Install NVIDIA GPU Drivers &amp; CUDA</title>
      <link>http://markbuckler.com/post/install-cuda/</link>
      <pubDate>Sat, 01 Apr 2017 16:25:31 -0400</pubDate>
      
      <guid>http://markbuckler.com/post/install-cuda/</guid>
      <description>&lt;p&gt;Anyone who&amp;rsquo;s set up a new Linux based, GPU enabled, deep learning system
knows the horror that is driver installation. While it is technically
possible to install NVIDIA drivers and CUDA from your package manager,
the most up to date versions aren&amp;rsquo;t available and in the worst case you
might even break graphics on your machine. After a great deal of
difficulties installing and reinstalling, I finally found a viable
strategy: installing both CUDA and proprietary Linux drivers from an
NVIDA run file without OpenGL libraries.&lt;/p&gt;

&lt;p&gt;The installation instructions shown below are largely taken from a two
year old
&lt;a href=&#34;https://devtalk.nvidia.com/default/topic/878117/-solved-titan-x-for-cuda-7-5-login-loop-error-ubuntu-14-04-/&#34; target=&#34;_blank&#34;&gt;forum
post&lt;/a&gt;
on NVIDIA&amp;rsquo;s developer forum with a question asked by a user called
NeuroSurfer and answered by txbob. I think it is worth reposting the
instructions here because I&amp;rsquo;ve added a few things, and also because
I think a formal post will help bring more exposure to this solution.&lt;/p&gt;

&lt;p&gt;Without further ado, here is how to install NVIDIA drivers and CUDA on
your Linux machine. I have tested these instructions on systems running
Ubuntu 14.04 and 16.04 and with Titan X and GTX 980 cards.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Preferably start with a fresh install of your OS, but if you are
hoping to avoid a full OS re-install you first need to purge your
system of any existing NVIDIA drivers installed via the package manager.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get remove --purge nvidia-*
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Download the run file for the CUDA version that you want. You can
find the download link
&lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. Make sure to get
the run file and not the debian installer. Change the permissions of it
so that it can be executed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chmod a+x .
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Verify that build-essential is installed&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install build-essential
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Remove your xorg.conf if it exists&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo rm /etc/X11/xorg.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create a blacklist file for nouveau (default Ubuntu graphics) at
&lt;code&gt;/etc/modprobe.d/blacklist-nouveau.conf&lt;/code&gt;. Put in the following contents:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;blacklist nouveau
options nouveau modeset=0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Update your kernel&amp;rsquo;s ramdisk&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo update-initramfs -u
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reboot your machine, nothing should have changed&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Use &lt;code&gt;Ctrl-Alt-F1&lt;/code&gt; to drop to a terminal, log in.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stop your display manager. Lightdm is default for Ubuntu&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo service lightdm stop
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Navigate back to where you downloaded your run file. Run it and
explicitly avoid installing OpenGL libraries with the command line
option.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo ./cuda-X.Y.ZZ_linux.run --no-opengl-libs
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Accept the EULA&lt;/li&gt;
&lt;li&gt;Install the driver? Yes&lt;/li&gt;
&lt;li&gt;Update the Xserver config? No&lt;/li&gt;
&lt;li&gt;Install CUDA? Yes&lt;/li&gt;
&lt;li&gt;Install the CUDA samples? Yes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Install nvidia-modprobe. This avoids that annoying
&amp;ldquo;cudaGetDeviceCount returned 30 -&amp;gt; unknown error&amp;rdquo; issue.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install nvidia-modprobe
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Edit your ~/.bashrc to update your path variables&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export PATH=/usr/local/cuda-7.0/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-7.0/lib64:$LD_LIBRARY_PATH
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Update your paths&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Check that the CUDA version is correct.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nvcc -V
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Check that your GPU&amp;rsquo;s are visible to the system and have the right
driver versions.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nvidia-smi
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reboot your system, pray to our Lord and Savior Elon Musk. If his
kindly gaze falls upon you, you will have a fully functional CUDA
enabled Linux machine. Enjoy!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Troubleshooting and final thoughts&lt;/p&gt;

&lt;p&gt;If you experience a login loop (are able to get to the login screen but
when you try to log in you are kicked back to the login screen) then it
is likely that you forgot to include the &lt;code&gt;--no-opengl-libs&lt;/code&gt; command when
running the installation runfile.&lt;/p&gt;

&lt;p&gt;If after booting you see a black screen with a blinking unresponsive
cursor, then you likely have something wrong with your display manager.
Re-install lightdm or install and switch to gdm.&lt;/p&gt;

&lt;p&gt;Because this installation doesn&amp;rsquo;t go through the package manager you may
experience issues when upgrading your kernel. If you&amp;rsquo;d like a way to
automatically re-install on an update you may be interested in &lt;a href=&#34;https://ubuntuforums.org/showthread.php?t=835573&#34; target=&#34;_blank&#34;&gt;this
solution&lt;/a&gt; as well.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
